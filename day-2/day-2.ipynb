{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cff2c86f-a777-4a13-94d8-03a06c901a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain langchain-openai langchain-openai langchain_chroma langchain-text-splitters langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed65d91-4502-43de-8bb1-d8af22f6288c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21705e84-6ed6-47e2-a9ff-087ded3a71b9",
   "metadata": {},
   "source": [
    "## RAG 실습-1: 웹페이지 크롤링(RecSys 논문 작성법 검색)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f921f80e-c0f2-4fc5-8062-8fe6cc047e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load, chunk and index the contents for the publication guidelines of RecSys`24\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://recsys.acm.org/recsys24/call/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            # class_=(\"post-content\", \"post-title\", \"post-header\"),\n",
    "            class_=(\"tabs-content\",),\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "348ad7d0-f1da-4ee0-ab66-2c9f1c29530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e85c9a5-0293-499d-bcc7-c3bd1404208a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bc-user/.local/lib/python3.10/site-packages/langsmith/client.py:333: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n",
      "/home/bc-user/.local/lib/python3.10/site-packages/langsmith/client.py:5434: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  prompt = loads(json.dumps(prompt_object.manifest))\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7396b97f-ab28-4b25-b13e-26ac41b7a5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are allowed to submit a short paper of up to 4 pages, plus an additional page for references.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"How many pages we are allowed to submit a short paper?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a5e8ae-18d9-4451-927b-c06f669e3e92",
   "metadata": {},
   "source": [
    "## RAG 실습-2: 로컬 파일 검색(카카오 베네핏)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71e9e6d7-b793-42fc-b860-d34dddc4521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"카카오 베네핏: 크루들의 업무 몰입 뿐 아니라 자기개발, 여가/취미 활동 지원을 위한 카카오베네핏! 연 360만원까지 사용할 수 있는 개인별 베네핏 카드를 지급합니다.\" > info.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "271e6aa6-6990-469c-a6ec-c7e00ce9404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "loader = TextLoader(\"info.txt\")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "docs = retriever.invoke(\"카카오 베테핏\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c82f7f-d2ef-43fe-afdb-ab33ab3ba52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bc-user/.local/lib/python3.10/site-packages/langsmith/client.py:333: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d42b17fa-ec55-4461-96ca-c07c90862e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'카카오 베네핏은 크루들의 업무 몰입과 자기개발, 여가/취미 활동을 지원하기 위한 프로그램입니다. 개인별로 연 360만원까지 사용할 수 있는 베네핏 카드를 지급합니다. 이를 통해 다양한 활동을 지원받을 수 있습니다.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"카카오 베네핏에 대해 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1ed93-438e-4d19-81ea-d9f99e7041d9",
   "metadata": {},
   "source": [
    "## Day 2 프로젝트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6d59ea1-0c60-405c-901c-dc3126bd6185",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12c1a5b4-9f31-4e13-af53-68890a91e8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2731, which is longer than the specified 1000\n",
      "Created a chunk of size 1538, which is longer than the specified 1000\n",
      "Created a chunk of size 1380, which is longer than the specified 1000\n",
      "Created a chunk of size 2352, which is longer than the specified 1000\n",
      "Created a chunk of size 1953, which is longer than the specified 1000\n",
      "Created a chunk of size 1067, which is longer than the specified 1000\n",
      "Created a chunk of size 1475, which is longer than the specified 1000\n",
      "Created a chunk of size 2881, which is longer than the specified 1000\n",
      "Created a chunk of size 1980, which is longer than the specified 1000\n",
      "Created a chunk of size 4145, which is longer than the specified 1000\n",
      "Created a chunk of size 2159, which is longer than the specified 1000\n",
      "Created a chunk of size 1317, which is longer than the specified 1000\n",
      "Created a chunk of size 1112, which is longer than the specified 1000\n",
      "Created a chunk of size 1043, which is longer than the specified 1000\n",
      "Created a chunk of size 1578, which is longer than the specified 1000\n",
      "Created a chunk of size 1141, which is longer than the specified 1000\n",
      "Created a chunk of size 1464, which is longer than the specified 1000\n",
      "Created a chunk of size 1756, which is longer than the specified 1000\n",
      "Created a chunk of size 1743, which is longer than the specified 1000\n",
      "Created a chunk of size 2407, which is longer than the specified 1000\n",
      "Created a chunk of size 1682, which is longer than the specified 1000\n",
      "Created a chunk of size 1014, which is longer than the specified 1000\n",
      "Created a chunk of size 1036, which is longer than the specified 1000\n",
      "Created a chunk of size 1214, which is longer than the specified 1000\n",
      "Created a chunk of size 1189, which is longer than the specified 1000\n",
      "Created a chunk of size 1986, which is longer than the specified 1000\n",
      "Created a chunk of size 1084, which is longer than the specified 1000\n",
      "Created a chunk of size 1278, which is longer than the specified 1000\n",
      "Created a chunk of size 1462, which is longer than the specified 1000\n",
      "/home/bc-user/.local/lib/python3.10/site-packages/langsmith/client.py:333: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=urls,\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\"),\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27988e15-e014-41e7-aac2-d4d4dbfb8fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_handler(query: str, check_hallucination: bool = True) -> None:\n",
    "    PROMPT_FOR_RELEVANCE_CHECK = \"\"\"\n",
    "    Would you examine whether QUERY and ANSWER are relevant with each other?\n",
    "    If QUERY and ANSWER are relevant, answer 'yes', otherwise 'no'.\n",
    "    \n",
    "    QUERY: \\'{QUERY}\\'\n",
    "    \n",
    "    ANSWER: \\'{ANSWER}\\'\n",
    "    \"\"\"\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    answer = rag_chain.invoke(query)\n",
    "    output = llm.invoke(\n",
    "        PROMPT_FOR_RELEVANCE_CHECK.format(QUERY=query, ANSWER=answer)\n",
    "    ).content.lower()\n",
    "    if \"yes\" in output:\n",
    "        raws = '\\n\\n'.join([doc.page_content for doc in retriever.invoke(query)])\n",
    "        output = llm.invoke(\n",
    "            PROMPT_FOR_RELEVANCE_CHECK.format(QUERY=query, ANSWER=raws)\n",
    "        ).content.lower() if check_hallucination else \"yes\"\n",
    "        if output in \"yes\":\n",
    "            print(answer)\n",
    "        else:\n",
    "            print(\"hallucination!\")\n",
    "    elif \"no\" in output:\n",
    "        print(\"Sorry. No found relavant information.\")\n",
    "    else:\n",
    "        raise Exception(f\"{output=}, \\n\\n {answer=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "176469b3-724d-4fa9-bf4f-22ddbe46bd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry. No found relavant information.\n"
     ]
    }
   ],
   "source": [
    "rag_handler(\"What is your name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fd772ea-36cc-4586-8571-72f171579bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry. No found relavant information.\n"
     ]
    }
   ],
   "source": [
    "rag_handler(\"I want to know how old superman is.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47939876-9217-4e2f-8031-297f75ec604e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hallucination!\n"
     ]
    }
   ],
   "source": [
    "rag_handler(\"Could you explain what is the agent system?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "126a7c76-106d-4010-a3ae-a8bd9c568d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To improve click-through rates (CTR) in a recommender system, consider the diversity of recommendations and the biases present in the model. Incorporating human feedback can enhance the training process by filtering out harmful content and refining the model's outputs. Additionally, calibrating label probabilities and addressing biases such as majority label bias and recency bias can significantly impact performance.\n"
     ]
    }
   ],
   "source": [
    "rag_handler(\"In case we deploy a recommender system, what aspects should be consider to improve CTR?\", check_hallucination=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a08a7d09-4abe-4f02-8cbb-91dedbdf9a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hallucination!\n"
     ]
    }
   ],
   "source": [
    "rag_handler(\"In case we deploy a recommender system, what aspects should be consider to improve CTR?\", check_hallucination=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c7be86-2510-4780-8322-5bd475d45539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
